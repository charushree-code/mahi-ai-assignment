{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSgrnIzism5nrB03Z6xzPI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charushree-code/mahi-ai-assignment/blob/main/assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drFH17Hl84y1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Activation,Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkExCsnm-b4U"
      },
      "source": [
        "df=pd.read_csv('iris.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlxpdZ1m-6GR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "4a4067ef-eb53-482c-9880-deb46a7fe14b"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width    species\n",
              "0             5.1          3.5           1.4          0.2     setosa\n",
              "1             4.9          3.0           1.4          0.2     setosa\n",
              "2             4.7          3.2           1.3          0.2     setosa\n",
              "3             4.6          3.1           1.5          0.2     setosa\n",
              "4             5.0          3.6           1.4          0.2     setosa\n",
              "..            ...          ...           ...          ...        ...\n",
              "145           6.7          3.0           5.2          2.3  virginica\n",
              "146           6.3          2.5           5.0          1.9  virginica\n",
              "147           6.5          3.0           5.2          2.0  virginica\n",
              "148           6.2          3.4           5.4          2.3  virginica\n",
              "149           5.9          3.0           5.1          1.8  virginica\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 251
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7eY9bYt_IGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8327acff-c6f9-450a-d2e6-54eb0074c434"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sepal_length    0\n",
              "sepal_width     0\n",
              "petal_length    0\n",
              "petal_width     0\n",
              "species         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAVElnuN_v3G"
      },
      "source": [
        "x=df.drop('species',axis=1).values.astype(float)\n",
        "y=df['species'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iLl02IgAM1s",
        "outputId": "385a84ab-8e0b-451a-a09a-95b94fde885c"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utda401NBgN-",
        "outputId": "13a58379-e3ae-495f-d240-e019d22196b9"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOxMtORPGY6O"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gnf013OtGe8U",
        "outputId": "7ba6af94-62a6-4be1-ea08-9bd9546e8e01"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O5juAU4GhRG",
        "outputId": "6bcff3df-0cc6-425d-abca-6d4ac3063b7b"
      },
      "source": [
        "\n",
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vqot-wxGjiP",
        "outputId": "5e0291a0-1a0d-4cc5-b353-a4738d682052"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMS-f6osGmzI",
        "outputId": "c001843e-325c-49c1-8748-44dc5b9d9f74"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9v6PY9HId9v"
      },
      "source": [
        "label encoding followed by one hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqag_BMzBg7z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f04d2d-4e6b-4172-d211-0d96a7afddcf"
      },
      "source": [
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "encoded_y_train = label_encoder.transform(y_train)\n",
        "print(encoded_y_train)\n",
        "y_train=to_categorical(encoded_y_train)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 2 1 2 1 2 1 0 2 1 0 0 0 1 2 0 0 0 1 0 1 2 0 1 2 0 2 2 1 1 2 1 0 1 2 0\n",
            " 0 1 1 0 2 0 0 1 1 2 1 2 2 1 0 0 2 2 0 0 0 1 2 0 2 2 0 1 1 2 1 2 0 2 1 2 1\n",
            " 1 1 0 1 1 0 1 2 2 0 1 2 2 0 2 0 1 2 2 1 2 1 1 2 2 0 1 2 0 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk3Ja4UIGtWG"
      },
      "source": [
        "#y test \n",
        "label_encoder.fit(y_test)\n",
        "encoded_y_test = label_encoder.transform(y_test)\n",
        "#one hot encoded)\n",
        "y_test=to_categorical(encoded_y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNkEXXDZKMOT"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqhXkXWOKmd5"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Noq5OSEaLP_b"
      },
      "source": [
        "scaler=MinMaxScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFqLEV3XKtLU"
      },
      "source": [
        "designing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw_wtJKLMqRJ"
      },
      "source": [
        "early_stop=EarlyStopping(monitor='val_loss',patience=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd_vhN6qK3rE"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Dense(40,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(20,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug-bcAiIM6--",
        "outputId": "ea48205b-ba45-43f8-8e1b-c3832142389f"
      },
      "source": [
        "model.fit(X_train,y_train,epochs=600,validation_data=(X_test,y_test),callbacks=[early_stop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "4/4 [==============================] - 1s 50ms/step - loss: 1.1491 - val_loss: 1.0900\n",
            "Epoch 2/600\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1600 - val_loss: 1.0689\n",
            "Epoch 3/600\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.1015 - val_loss: 1.0504\n",
            "Epoch 4/600\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0993 - val_loss: 1.0325\n",
            "Epoch 5/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0657 - val_loss: 1.0159\n",
            "Epoch 6/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0704 - val_loss: 1.0002\n",
            "Epoch 7/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0408 - val_loss: 0.9850\n",
            "Epoch 8/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0152 - val_loss: 0.9696\n",
            "Epoch 9/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0566 - val_loss: 0.9548\n",
            "Epoch 10/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.0177 - val_loss: 0.9405\n",
            "Epoch 11/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.9790 - val_loss: 0.9267\n",
            "Epoch 12/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0172 - val_loss: 0.9128\n",
            "Epoch 13/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.9474 - val_loss: 0.8995\n",
            "Epoch 14/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.9482 - val_loss: 0.8857\n",
            "Epoch 15/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.9592 - val_loss: 0.8701\n",
            "Epoch 16/600\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.9034 - val_loss: 0.8543\n",
            "Epoch 17/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.9689 - val_loss: 0.8398\n",
            "Epoch 18/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.9186 - val_loss: 0.8254\n",
            "Epoch 19/600\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.9028 - val_loss: 0.8104\n",
            "Epoch 20/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8307 - val_loss: 0.7948\n",
            "Epoch 21/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8534 - val_loss: 0.7790\n",
            "Epoch 22/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8599 - val_loss: 0.7642\n",
            "Epoch 23/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8404 - val_loss: 0.7487\n",
            "Epoch 24/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8396 - val_loss: 0.7328\n",
            "Epoch 25/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8647 - val_loss: 0.7180\n",
            "Epoch 26/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.8335 - val_loss: 0.7038\n",
            "Epoch 27/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7959 - val_loss: 0.6889\n",
            "Epoch 28/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8236 - val_loss: 0.6743\n",
            "Epoch 29/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7779 - val_loss: 0.6601\n",
            "Epoch 30/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7691 - val_loss: 0.6469\n",
            "Epoch 31/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.8103 - val_loss: 0.6348\n",
            "Epoch 32/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7996 - val_loss: 0.6224\n",
            "Epoch 33/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7801 - val_loss: 0.6105\n",
            "Epoch 34/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7586 - val_loss: 0.5988\n",
            "Epoch 35/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7088 - val_loss: 0.5875\n",
            "Epoch 36/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7270 - val_loss: 0.5769\n",
            "Epoch 37/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6940 - val_loss: 0.5661\n",
            "Epoch 38/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7968 - val_loss: 0.5553\n",
            "Epoch 39/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7981 - val_loss: 0.5460\n",
            "Epoch 40/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7415 - val_loss: 0.5370\n",
            "Epoch 41/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.7169 - val_loss: 0.5279\n",
            "Epoch 42/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7035 - val_loss: 0.5196\n",
            "Epoch 43/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6376 - val_loss: 0.5119\n",
            "Epoch 44/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.7347 - val_loss: 0.5049\n",
            "Epoch 45/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6609 - val_loss: 0.4969\n",
            "Epoch 46/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6173 - val_loss: 0.4888\n",
            "Epoch 47/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6908 - val_loss: 0.4810\n",
            "Epoch 48/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6726 - val_loss: 0.4744\n",
            "Epoch 49/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6269 - val_loss: 0.4683\n",
            "Epoch 50/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5851 - val_loss: 0.4618\n",
            "Epoch 51/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.6531 - val_loss: 0.4551\n",
            "Epoch 52/600\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.6583 - val_loss: 0.4493\n",
            "Epoch 53/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6122 - val_loss: 0.4444\n",
            "Epoch 54/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5770 - val_loss: 0.4391\n",
            "Epoch 55/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5930 - val_loss: 0.4337\n",
            "Epoch 56/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6246 - val_loss: 0.4291\n",
            "Epoch 57/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6398 - val_loss: 0.4252\n",
            "Epoch 58/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6357 - val_loss: 0.4212\n",
            "Epoch 59/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6017 - val_loss: 0.4169\n",
            "Epoch 60/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.6135 - val_loss: 0.4132\n",
            "Epoch 61/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6764 - val_loss: 0.4106\n",
            "Epoch 62/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6046 - val_loss: 0.4079\n",
            "Epoch 63/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5299 - val_loss: 0.4051\n",
            "Epoch 64/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5818 - val_loss: 0.4022\n",
            "Epoch 65/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5996 - val_loss: 0.3993\n",
            "Epoch 66/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6136 - val_loss: 0.3966\n",
            "Epoch 67/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5666 - val_loss: 0.3941\n",
            "Epoch 68/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5848 - val_loss: 0.3917\n",
            "Epoch 69/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5946 - val_loss: 0.3897\n",
            "Epoch 70/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5970 - val_loss: 0.3874\n",
            "Epoch 71/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5884 - val_loss: 0.3855\n",
            "Epoch 72/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5399 - val_loss: 0.3831\n",
            "Epoch 73/600\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5556 - val_loss: 0.3805\n",
            "Epoch 74/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5271 - val_loss: 0.3779\n",
            "Epoch 75/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5054 - val_loss: 0.3752\n",
            "Epoch 76/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5463 - val_loss: 0.3727\n",
            "Epoch 77/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5404 - val_loss: 0.3702\n",
            "Epoch 78/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5610 - val_loss: 0.3680\n",
            "Epoch 79/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5044 - val_loss: 0.3660\n",
            "Epoch 80/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5135 - val_loss: 0.3640\n",
            "Epoch 81/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5541 - val_loss: 0.3620\n",
            "Epoch 82/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5239 - val_loss: 0.3598\n",
            "Epoch 83/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5237 - val_loss: 0.3575\n",
            "Epoch 84/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4944 - val_loss: 0.3545\n",
            "Epoch 85/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5016 - val_loss: 0.3516\n",
            "Epoch 86/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5165 - val_loss: 0.3495\n",
            "Epoch 87/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5387 - val_loss: 0.3476\n",
            "Epoch 88/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4766 - val_loss: 0.3460\n",
            "Epoch 89/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4835 - val_loss: 0.3443\n",
            "Epoch 90/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5525 - val_loss: 0.3428\n",
            "Epoch 91/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5380 - val_loss: 0.3422\n",
            "Epoch 92/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5022 - val_loss: 0.3429\n",
            "Epoch 93/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4929 - val_loss: 0.3441\n",
            "Epoch 94/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5089 - val_loss: 0.3445\n",
            "Epoch 95/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4482 - val_loss: 0.3454\n",
            "Epoch 96/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5526 - val_loss: 0.3445\n",
            "Epoch 97/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4782 - val_loss: 0.3429\n",
            "Epoch 98/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4754 - val_loss: 0.3415\n",
            "Epoch 99/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4746 - val_loss: 0.3389\n",
            "Epoch 100/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4967 - val_loss: 0.3354\n",
            "Epoch 101/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5040 - val_loss: 0.3327\n",
            "Epoch 102/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4450 - val_loss: 0.3298\n",
            "Epoch 103/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4972 - val_loss: 0.3264\n",
            "Epoch 104/600\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5434 - val_loss: 0.3242\n",
            "Epoch 105/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4254 - val_loss: 0.3219\n",
            "Epoch 106/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4880 - val_loss: 0.3208\n",
            "Epoch 107/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4867 - val_loss: 0.3206\n",
            "Epoch 108/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4752 - val_loss: 0.3200\n",
            "Epoch 109/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4300 - val_loss: 0.3184\n",
            "Epoch 110/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5129 - val_loss: 0.3156\n",
            "Epoch 111/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4624 - val_loss: 0.3125\n",
            "Epoch 112/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5089 - val_loss: 0.3097\n",
            "Epoch 113/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4348 - val_loss: 0.3073\n",
            "Epoch 114/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4332 - val_loss: 0.3044\n",
            "Epoch 115/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4645 - val_loss: 0.3013\n",
            "Epoch 116/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4563 - val_loss: 0.2994\n",
            "Epoch 117/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4779 - val_loss: 0.2971\n",
            "Epoch 118/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4131 - val_loss: 0.2953\n",
            "Epoch 119/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4809 - val_loss: 0.2938\n",
            "Epoch 120/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4450 - val_loss: 0.2924\n",
            "Epoch 121/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5059 - val_loss: 0.2903\n",
            "Epoch 122/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4657 - val_loss: 0.2885\n",
            "Epoch 123/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4489 - val_loss: 0.2871\n",
            "Epoch 124/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4824 - val_loss: 0.2866\n",
            "Epoch 125/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4172 - val_loss: 0.2850\n",
            "Epoch 126/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4378 - val_loss: 0.2835\n",
            "Epoch 127/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4751 - val_loss: 0.2821\n",
            "Epoch 128/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4598 - val_loss: 0.2818\n",
            "Epoch 129/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4286 - val_loss: 0.2808\n",
            "Epoch 130/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4280 - val_loss: 0.2791\n",
            "Epoch 131/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4415 - val_loss: 0.2774\n",
            "Epoch 132/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4007 - val_loss: 0.2746\n",
            "Epoch 133/600\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4364 - val_loss: 0.2725\n",
            "Epoch 134/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4452 - val_loss: 0.2705\n",
            "Epoch 135/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4644 - val_loss: 0.2683\n",
            "Epoch 136/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4187 - val_loss: 0.2663\n",
            "Epoch 137/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4143 - val_loss: 0.2651\n",
            "Epoch 138/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4212 - val_loss: 0.2640\n",
            "Epoch 139/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4383 - val_loss: 0.2621\n",
            "Epoch 140/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4119 - val_loss: 0.2614\n",
            "Epoch 141/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4191 - val_loss: 0.2596\n",
            "Epoch 142/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3956 - val_loss: 0.2573\n",
            "Epoch 143/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4063 - val_loss: 0.2570\n",
            "Epoch 144/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4185 - val_loss: 0.2591\n",
            "Epoch 145/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4270 - val_loss: 0.2577\n",
            "Epoch 146/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3899 - val_loss: 0.2531\n",
            "Epoch 147/600\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4175 - val_loss: 0.2476\n",
            "Epoch 148/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4179 - val_loss: 0.2444\n",
            "Epoch 149/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4085 - val_loss: 0.2433\n",
            "Epoch 150/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4392 - val_loss: 0.2419\n",
            "Epoch 151/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4024 - val_loss: 0.2408\n",
            "Epoch 152/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4212 - val_loss: 0.2402\n",
            "Epoch 153/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3849 - val_loss: 0.2396\n",
            "Epoch 154/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3912 - val_loss: 0.2386\n",
            "Epoch 155/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3781 - val_loss: 0.2376\n",
            "Epoch 156/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3823 - val_loss: 0.2357\n",
            "Epoch 157/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4522 - val_loss: 0.2334\n",
            "Epoch 158/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4103 - val_loss: 0.2318\n",
            "Epoch 159/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4223 - val_loss: 0.2296\n",
            "Epoch 160/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3523 - val_loss: 0.2289\n",
            "Epoch 161/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3701 - val_loss: 0.2280\n",
            "Epoch 162/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3905 - val_loss: 0.2278\n",
            "Epoch 163/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3768 - val_loss: 0.2275\n",
            "Epoch 164/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4075 - val_loss: 0.2269\n",
            "Epoch 165/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3491 - val_loss: 0.2275\n",
            "Epoch 166/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3742 - val_loss: 0.2276\n",
            "Epoch 167/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3500 - val_loss: 0.2263\n",
            "Epoch 168/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4044 - val_loss: 0.2225\n",
            "Epoch 169/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4362 - val_loss: 0.2187\n",
            "Epoch 170/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3457 - val_loss: 0.2145\n",
            "Epoch 171/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3304 - val_loss: 0.2115\n",
            "Epoch 172/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3747 - val_loss: 0.2075\n",
            "Epoch 173/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3728 - val_loss: 0.2046\n",
            "Epoch 174/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3979 - val_loss: 0.2032\n",
            "Epoch 175/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3624 - val_loss: 0.2033\n",
            "Epoch 176/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4056 - val_loss: 0.2040\n",
            "Epoch 177/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3973 - val_loss: 0.2051\n",
            "Epoch 178/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3616 - val_loss: 0.2047\n",
            "Epoch 179/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2833 - val_loss: 0.2037\n",
            "Epoch 180/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3238 - val_loss: 0.2022\n",
            "Epoch 181/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3354 - val_loss: 0.1991\n",
            "Epoch 182/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3711 - val_loss: 0.1961\n",
            "Epoch 183/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3587 - val_loss: 0.1931\n",
            "Epoch 184/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3300 - val_loss: 0.1908\n",
            "Epoch 185/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3558 - val_loss: 0.1899\n",
            "Epoch 186/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3254 - val_loss: 0.1876\n",
            "Epoch 187/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3537 - val_loss: 0.1857\n",
            "Epoch 188/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3327 - val_loss: 0.1854\n",
            "Epoch 189/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3192 - val_loss: 0.1859\n",
            "Epoch 190/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3462 - val_loss: 0.1831\n",
            "Epoch 191/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3518 - val_loss: 0.1808\n",
            "Epoch 192/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3583 - val_loss: 0.1787\n",
            "Epoch 193/600\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3881 - val_loss: 0.1747\n",
            "Epoch 194/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3112 - val_loss: 0.1724\n",
            "Epoch 195/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3723 - val_loss: 0.1703\n",
            "Epoch 196/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3576 - val_loss: 0.1694\n",
            "Epoch 197/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3273 - val_loss: 0.1683\n",
            "Epoch 198/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3447 - val_loss: 0.1674\n",
            "Epoch 199/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3207 - val_loss: 0.1673\n",
            "Epoch 200/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3354 - val_loss: 0.1671\n",
            "Epoch 201/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3263 - val_loss: 0.1669\n",
            "Epoch 202/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3472 - val_loss: 0.1672\n",
            "Epoch 203/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3056 - val_loss: 0.1662\n",
            "Epoch 204/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3303 - val_loss: 0.1636\n",
            "Epoch 205/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2978 - val_loss: 0.1603\n",
            "Epoch 206/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3197 - val_loss: 0.1575\n",
            "Epoch 207/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3261 - val_loss: 0.1568\n",
            "Epoch 208/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3071 - val_loss: 0.1564\n",
            "Epoch 209/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3317 - val_loss: 0.1575\n",
            "Epoch 210/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2558 - val_loss: 0.1587\n",
            "Epoch 211/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3586 - val_loss: 0.1585\n",
            "Epoch 212/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3585 - val_loss: 0.1576\n",
            "Epoch 213/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2758 - val_loss: 0.1536\n",
            "Epoch 214/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2777 - val_loss: 0.1506\n",
            "Epoch 215/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3256 - val_loss: 0.1484\n",
            "Epoch 216/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2870 - val_loss: 0.1478\n",
            "Epoch 217/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3073 - val_loss: 0.1480\n",
            "Epoch 218/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3115 - val_loss: 0.1500\n",
            "Epoch 219/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3538 - val_loss: 0.1515\n",
            "Epoch 220/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3495 - val_loss: 0.1546\n",
            "Epoch 221/600\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2822 - val_loss: 0.1623\n",
            "Epoch 222/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3091 - val_loss: 0.1597\n",
            "Epoch 223/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3023 - val_loss: 0.1546\n",
            "Epoch 224/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2875 - val_loss: 0.1491\n",
            "Epoch 225/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3181 - val_loss: 0.1443\n",
            "Epoch 226/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3015 - val_loss: 0.1416\n",
            "Epoch 227/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3183 - val_loss: 0.1399\n",
            "Epoch 228/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2671 - val_loss: 0.1376\n",
            "Epoch 229/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3098 - val_loss: 0.1358\n",
            "Epoch 230/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2950 - val_loss: 0.1340\n",
            "Epoch 231/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3110 - val_loss: 0.1329\n",
            "Epoch 232/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2580 - val_loss: 0.1318\n",
            "Epoch 233/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2674 - val_loss: 0.1317\n",
            "Epoch 234/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3183 - val_loss: 0.1319\n",
            "Epoch 235/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3024 - val_loss: 0.1319\n",
            "Epoch 236/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2238 - val_loss: 0.1319\n",
            "Epoch 237/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2737 - val_loss: 0.1304\n",
            "Epoch 238/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2708 - val_loss: 0.1280\n",
            "Epoch 239/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2725 - val_loss: 0.1258\n",
            "Epoch 240/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2828 - val_loss: 0.1234\n",
            "Epoch 241/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2537 - val_loss: 0.1226\n",
            "Epoch 242/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2899 - val_loss: 0.1231\n",
            "Epoch 243/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2847 - val_loss: 0.1236\n",
            "Epoch 244/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2515 - val_loss: 0.1239\n",
            "Epoch 245/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3065 - val_loss: 0.1234\n",
            "Epoch 246/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2860 - val_loss: 0.1244\n",
            "Epoch 247/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2514 - val_loss: 0.1241\n",
            "Epoch 248/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2594 - val_loss: 0.1228\n",
            "Epoch 249/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3001 - val_loss: 0.1192\n",
            "Epoch 250/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3167 - val_loss: 0.1189\n",
            "Epoch 251/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2933 - val_loss: 0.1181\n",
            "Epoch 252/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2572 - val_loss: 0.1164\n",
            "Epoch 253/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2875 - val_loss: 0.1162\n",
            "Epoch 254/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2459 - val_loss: 0.1152\n",
            "Epoch 255/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2779 - val_loss: 0.1163\n",
            "Epoch 256/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2786 - val_loss: 0.1167\n",
            "Epoch 257/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2798 - val_loss: 0.1159\n",
            "Epoch 258/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2528 - val_loss: 0.1160\n",
            "Epoch 259/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2776 - val_loss: 0.1145\n",
            "Epoch 260/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2520 - val_loss: 0.1134\n",
            "Epoch 261/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2353 - val_loss: 0.1121\n",
            "Epoch 262/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2298 - val_loss: 0.1118\n",
            "Epoch 263/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2430 - val_loss: 0.1111\n",
            "Epoch 264/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2932 - val_loss: 0.1089\n",
            "Epoch 265/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2361 - val_loss: 0.1068\n",
            "Epoch 266/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2300 - val_loss: 0.1056\n",
            "Epoch 267/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2573 - val_loss: 0.1049\n",
            "Epoch 268/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2339 - val_loss: 0.1048\n",
            "Epoch 269/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2452 - val_loss: 0.1048\n",
            "Epoch 270/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2465 - val_loss: 0.1037\n",
            "Epoch 271/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1997 - val_loss: 0.1026\n",
            "Epoch 272/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2575 - val_loss: 0.1017\n",
            "Epoch 273/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2485 - val_loss: 0.1014\n",
            "Epoch 274/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2832 - val_loss: 0.1011\n",
            "Epoch 275/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3236 - val_loss: 0.1003\n",
            "Epoch 276/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2657 - val_loss: 0.1001\n",
            "Epoch 277/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2192 - val_loss: 0.1030\n",
            "Epoch 278/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1994 - val_loss: 0.1059\n",
            "Epoch 279/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2651 - val_loss: 0.1044\n",
            "Epoch 280/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2389 - val_loss: 0.1008\n",
            "Epoch 281/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2739 - val_loss: 0.0984\n",
            "Epoch 282/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2442 - val_loss: 0.0973\n",
            "Epoch 283/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2387 - val_loss: 0.0973\n",
            "Epoch 284/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2966 - val_loss: 0.0966\n",
            "Epoch 285/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2289 - val_loss: 0.0961\n",
            "Epoch 286/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2867 - val_loss: 0.0964\n",
            "Epoch 287/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3065 - val_loss: 0.0964\n",
            "Epoch 288/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1989 - val_loss: 0.0956\n",
            "Epoch 289/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2877 - val_loss: 0.0949\n",
            "Epoch 290/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2697 - val_loss: 0.0943\n",
            "Epoch 291/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2448 - val_loss: 0.0951\n",
            "Epoch 292/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2397 - val_loss: 0.0977\n",
            "Epoch 293/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2125 - val_loss: 0.0981\n",
            "Epoch 294/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2717 - val_loss: 0.0964\n",
            "Epoch 295/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2518 - val_loss: 0.0944\n",
            "Epoch 296/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2553 - val_loss: 0.0924\n",
            "Epoch 297/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2405 - val_loss: 0.0916\n",
            "Epoch 298/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2431 - val_loss: 0.0925\n",
            "Epoch 299/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1885 - val_loss: 0.0950\n",
            "Epoch 300/600\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2491 - val_loss: 0.0983\n",
            "Epoch 301/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2107 - val_loss: 0.0981\n",
            "Epoch 302/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2417 - val_loss: 0.0955\n",
            "Epoch 303/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2472 - val_loss: 0.0923\n",
            "Epoch 304/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2515 - val_loss: 0.0897\n",
            "Epoch 305/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2189 - val_loss: 0.0880\n",
            "Epoch 306/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2582 - val_loss: 0.0873\n",
            "Epoch 307/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2070 - val_loss: 0.0868\n",
            "Epoch 308/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2234 - val_loss: 0.0863\n",
            "Epoch 309/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2578 - val_loss: 0.0859\n",
            "Epoch 310/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2301 - val_loss: 0.0850\n",
            "Epoch 311/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2596 - val_loss: 0.0847\n",
            "Epoch 312/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2320 - val_loss: 0.0844\n",
            "Epoch 313/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2301 - val_loss: 0.0838\n",
            "Epoch 314/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2152 - val_loss: 0.0835\n",
            "Epoch 315/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2677 - val_loss: 0.0834\n",
            "Epoch 316/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2064 - val_loss: 0.0836\n",
            "Epoch 317/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2107 - val_loss: 0.0830\n",
            "Epoch 318/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2476 - val_loss: 0.0832\n",
            "Epoch 319/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2109 - val_loss: 0.0838\n",
            "Epoch 320/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2259 - val_loss: 0.0844\n",
            "Epoch 321/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2122 - val_loss: 0.0836\n",
            "Epoch 322/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1990 - val_loss: 0.0822\n",
            "Epoch 323/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2387 - val_loss: 0.0812\n",
            "Epoch 324/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2502 - val_loss: 0.0809\n",
            "Epoch 325/600\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2402 - val_loss: 0.0806\n",
            "Epoch 326/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2513 - val_loss: 0.0797\n",
            "Epoch 327/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2730 - val_loss: 0.0805\n",
            "Epoch 328/600\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2680 - val_loss: 0.0856\n",
            "Epoch 329/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2320 - val_loss: 0.0893\n",
            "Epoch 330/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2241 - val_loss: 0.0868\n",
            "Epoch 331/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2681 - val_loss: 0.0841\n",
            "Epoch 332/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1867 - val_loss: 0.0816\n",
            "Epoch 333/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2050 - val_loss: 0.0799\n",
            "Epoch 334/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2109 - val_loss: 0.0795\n",
            "Epoch 335/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2424 - val_loss: 0.0790\n",
            "Epoch 336/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1758 - val_loss: 0.0785\n",
            "Epoch 337/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2157 - val_loss: 0.0794\n",
            "Epoch 338/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2356 - val_loss: 0.0800\n",
            "Epoch 339/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2149 - val_loss: 0.0807\n",
            "Epoch 340/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1945 - val_loss: 0.0801\n",
            "Epoch 341/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2407 - val_loss: 0.0796\n",
            "Epoch 342/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2281 - val_loss: 0.0770\n",
            "Epoch 343/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1897 - val_loss: 0.0752\n",
            "Epoch 344/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1818 - val_loss: 0.0742\n",
            "Epoch 345/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1694 - val_loss: 0.0739\n",
            "Epoch 346/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2450 - val_loss: 0.0736\n",
            "Epoch 347/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2460 - val_loss: 0.0741\n",
            "Epoch 348/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2523 - val_loss: 0.0754\n",
            "Epoch 349/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2105 - val_loss: 0.0782\n",
            "Epoch 350/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2258 - val_loss: 0.0781\n",
            "Epoch 351/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2167 - val_loss: 0.0747\n",
            "Epoch 352/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2130 - val_loss: 0.0730\n",
            "Epoch 353/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2335 - val_loss: 0.0720\n",
            "Epoch 354/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2250 - val_loss: 0.0722\n",
            "Epoch 355/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1795 - val_loss: 0.0721\n",
            "Epoch 356/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2539 - val_loss: 0.0713\n",
            "Epoch 357/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2438 - val_loss: 0.0714\n",
            "Epoch 358/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2487 - val_loss: 0.0733\n",
            "Epoch 359/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2186 - val_loss: 0.0730\n",
            "Epoch 360/600\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1724 - val_loss: 0.0726\n",
            "Epoch 361/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2062 - val_loss: 0.0731\n",
            "Epoch 362/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1805 - val_loss: 0.0728\n",
            "Epoch 363/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2588 - val_loss: 0.0703\n",
            "Epoch 364/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1612 - val_loss: 0.0690\n",
            "Epoch 365/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1779 - val_loss: 0.0692\n",
            "Epoch 366/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2093 - val_loss: 0.0692\n",
            "Epoch 367/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2256 - val_loss: 0.0688\n",
            "Epoch 368/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2102 - val_loss: 0.0681\n",
            "Epoch 369/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2442 - val_loss: 0.0677\n",
            "Epoch 370/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1881 - val_loss: 0.0680\n",
            "Epoch 371/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2151 - val_loss: 0.0684\n",
            "Epoch 372/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2035 - val_loss: 0.0695\n",
            "Epoch 373/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2237 - val_loss: 0.0690\n",
            "Epoch 374/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1868 - val_loss: 0.0688\n",
            "Epoch 375/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1941 - val_loss: 0.0678\n",
            "Epoch 376/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1896 - val_loss: 0.0672\n",
            "Epoch 377/600\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1905 - val_loss: 0.0667\n",
            "Epoch 378/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1741 - val_loss: 0.0676\n",
            "Epoch 379/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1559 - val_loss: 0.0695\n",
            "Epoch 380/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1807 - val_loss: 0.0716\n",
            "Epoch 381/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2279 - val_loss: 0.0702\n",
            "Epoch 382/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1987 - val_loss: 0.0687\n",
            "Epoch 383/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1971 - val_loss: 0.0669\n",
            "Epoch 384/600\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2087 - val_loss: 0.0651\n",
            "Epoch 385/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2385 - val_loss: 0.0648\n",
            "Epoch 386/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1986 - val_loss: 0.0654\n",
            "Epoch 387/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1587 - val_loss: 0.0649\n",
            "Epoch 388/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2055 - val_loss: 0.0647\n",
            "Epoch 389/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1989 - val_loss: 0.0658\n",
            "Epoch 390/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2804 - val_loss: 0.0658\n",
            "Epoch 391/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1875 - val_loss: 0.0655\n",
            "Epoch 392/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1681 - val_loss: 0.0636\n",
            "Epoch 393/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2114 - val_loss: 0.0629\n",
            "Epoch 394/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2259 - val_loss: 0.0628\n",
            "Epoch 395/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2126 - val_loss: 0.0628\n",
            "Epoch 396/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1764 - val_loss: 0.0628\n",
            "Epoch 397/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1946 - val_loss: 0.0628\n",
            "Epoch 398/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1808 - val_loss: 0.0631\n",
            "Epoch 399/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1854 - val_loss: 0.0634\n",
            "Epoch 400/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2469 - val_loss: 0.0636\n",
            "Epoch 401/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2040 - val_loss: 0.0632\n",
            "Epoch 402/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1770 - val_loss: 0.0625\n",
            "Epoch 403/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1825 - val_loss: 0.0620\n",
            "Epoch 404/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2009 - val_loss: 0.0617\n",
            "Epoch 405/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2166 - val_loss: 0.0628\n",
            "Epoch 406/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2759 - val_loss: 0.0640\n",
            "Epoch 407/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2009 - val_loss: 0.0625\n",
            "Epoch 408/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1825 - val_loss: 0.0615\n",
            "Epoch 409/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1770 - val_loss: 0.0611\n",
            "Epoch 410/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1846 - val_loss: 0.0606\n",
            "Epoch 411/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1764 - val_loss: 0.0605\n",
            "Epoch 412/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1567 - val_loss: 0.0603\n",
            "Epoch 413/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2178 - val_loss: 0.0603\n",
            "Epoch 414/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1728 - val_loss: 0.0603\n",
            "Epoch 415/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2019 - val_loss: 0.0602\n",
            "Epoch 416/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1704 - val_loss: 0.0598\n",
            "Epoch 417/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1964 - val_loss: 0.0594\n",
            "Epoch 418/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1824 - val_loss: 0.0591\n",
            "Epoch 419/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1666 - val_loss: 0.0592\n",
            "Epoch 420/600\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1917 - val_loss: 0.0602\n",
            "Epoch 421/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1816 - val_loss: 0.0626\n",
            "Epoch 422/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2009 - val_loss: 0.0648\n",
            "Epoch 423/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1749 - val_loss: 0.0664\n",
            "Epoch 424/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2299 - val_loss: 0.0637\n",
            "Epoch 425/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2037 - val_loss: 0.0603\n",
            "Epoch 426/600\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1662 - val_loss: 0.0588\n",
            "Epoch 427/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1916 - val_loss: 0.0587\n",
            "Epoch 428/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2244 - val_loss: 0.0592\n",
            "Epoch 429/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1868 - val_loss: 0.0602\n",
            "Epoch 430/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1750 - val_loss: 0.0629\n",
            "Epoch 431/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2295 - val_loss: 0.0632\n",
            "Epoch 432/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1440 - val_loss: 0.0628\n",
            "Epoch 433/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1845 - val_loss: 0.0619\n",
            "Epoch 434/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2046 - val_loss: 0.0612\n",
            "Epoch 435/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2036 - val_loss: 0.0605\n",
            "Epoch 436/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1754 - val_loss: 0.0587\n",
            "Epoch 437/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2663 - val_loss: 0.0565\n",
            "Epoch 438/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2193 - val_loss: 0.0583\n",
            "Epoch 439/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2191 - val_loss: 0.0626\n",
            "Epoch 440/600\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1869 - val_loss: 0.0624\n",
            "Epoch 441/600\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1995 - val_loss: 0.0588\n",
            "Epoch 442/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2003 - val_loss: 0.0561\n",
            "Epoch 443/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2085 - val_loss: 0.0554\n",
            "Epoch 444/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1548 - val_loss: 0.0558\n",
            "Epoch 445/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1433 - val_loss: 0.0566\n",
            "Epoch 446/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1238 - val_loss: 0.0578\n",
            "Epoch 447/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1811 - val_loss: 0.0591\n",
            "Epoch 448/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1564 - val_loss: 0.0591\n",
            "Epoch 449/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1314 - val_loss: 0.0587\n",
            "Epoch 450/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1462 - val_loss: 0.0587\n",
            "Epoch 451/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1638 - val_loss: 0.0580\n",
            "Epoch 452/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1630 - val_loss: 0.0565\n",
            "Epoch 453/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1970 - val_loss: 0.0551\n",
            "Epoch 454/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1376 - val_loss: 0.0565\n",
            "Epoch 455/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1757 - val_loss: 0.0584\n",
            "Epoch 456/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2326 - val_loss: 0.0605\n",
            "Epoch 457/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1514 - val_loss: 0.0590\n",
            "Epoch 458/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1816 - val_loss: 0.0568\n",
            "Epoch 459/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1902 - val_loss: 0.0559\n",
            "Epoch 460/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1176 - val_loss: 0.0548\n",
            "Epoch 461/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2126 - val_loss: 0.0544\n",
            "Epoch 462/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1650 - val_loss: 0.0547\n",
            "Epoch 463/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1622 - val_loss: 0.0553\n",
            "Epoch 464/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1988 - val_loss: 0.0559\n",
            "Epoch 465/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1780 - val_loss: 0.0553\n",
            "Epoch 466/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1740 - val_loss: 0.0548\n",
            "Epoch 467/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1857 - val_loss: 0.0548\n",
            "Epoch 468/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2097 - val_loss: 0.0546\n",
            "Epoch 469/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1763 - val_loss: 0.0546\n",
            "Epoch 470/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1459 - val_loss: 0.0547\n",
            "Epoch 471/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1916 - val_loss: 0.0556\n",
            "Epoch 472/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1990 - val_loss: 0.0556\n",
            "Epoch 473/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1349 - val_loss: 0.0546\n",
            "Epoch 474/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2092 - val_loss: 0.0536\n",
            "Epoch 475/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1503 - val_loss: 0.0534\n",
            "Epoch 476/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1616 - val_loss: 0.0533\n",
            "Epoch 477/600\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1603 - val_loss: 0.0537\n",
            "Epoch 478/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1595 - val_loss: 0.0543\n",
            "Epoch 479/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1969 - val_loss: 0.0532\n",
            "Epoch 480/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1729 - val_loss: 0.0527\n",
            "Epoch 481/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2055 - val_loss: 0.0525\n",
            "Epoch 482/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1555 - val_loss: 0.0528\n",
            "Epoch 483/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1909 - val_loss: 0.0533\n",
            "Epoch 484/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1524 - val_loss: 0.0534\n",
            "Epoch 485/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2005 - val_loss: 0.0528\n",
            "Epoch 486/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1928 - val_loss: 0.0526\n",
            "Epoch 487/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1218 - val_loss: 0.0523\n",
            "Epoch 488/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1851 - val_loss: 0.0520\n",
            "Epoch 489/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1341 - val_loss: 0.0517\n",
            "Epoch 490/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1502 - val_loss: 0.0518\n",
            "Epoch 491/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1541 - val_loss: 0.0521\n",
            "Epoch 492/600\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1809 - val_loss: 0.0525\n",
            "Epoch 493/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1932 - val_loss: 0.0523\n",
            "Epoch 494/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1897 - val_loss: 0.0549\n",
            "Epoch 495/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2189 - val_loss: 0.0578\n",
            "Epoch 496/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1684 - val_loss: 0.0578\n",
            "Epoch 497/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1452 - val_loss: 0.0544\n",
            "Epoch 498/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2405 - val_loss: 0.0517\n",
            "Epoch 499/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1664 - val_loss: 0.0511\n",
            "Epoch 500/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1619 - val_loss: 0.0510\n",
            "Epoch 501/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1908 - val_loss: 0.0508\n",
            "Epoch 502/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1853 - val_loss: 0.0510\n",
            "Epoch 503/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2356 - val_loss: 0.0497\n",
            "Epoch 504/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1510 - val_loss: 0.0484\n",
            "Epoch 505/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2050 - val_loss: 0.0479\n",
            "Epoch 506/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1444 - val_loss: 0.0478\n",
            "Epoch 507/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1596 - val_loss: 0.0478\n",
            "Epoch 508/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1705 - val_loss: 0.0472\n",
            "Epoch 509/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2117 - val_loss: 0.0466\n",
            "Epoch 510/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1471 - val_loss: 0.0465\n",
            "Epoch 511/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1277 - val_loss: 0.0464\n",
            "Epoch 512/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2282 - val_loss: 0.0463\n",
            "Epoch 513/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1923 - val_loss: 0.0464\n",
            "Epoch 514/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1689 - val_loss: 0.0466\n",
            "Epoch 515/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1394 - val_loss: 0.0470\n",
            "Epoch 516/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0915 - val_loss: 0.0477\n",
            "Epoch 517/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1571 - val_loss: 0.0485\n",
            "Epoch 518/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1840 - val_loss: 0.0490\n",
            "Epoch 519/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2015 - val_loss: 0.0487\n",
            "Epoch 520/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1629 - val_loss: 0.0483\n",
            "Epoch 521/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1501 - val_loss: 0.0477\n",
            "Epoch 522/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2214 - val_loss: 0.0467\n",
            "Epoch 523/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1850 - val_loss: 0.0465\n",
            "Epoch 524/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1635 - val_loss: 0.0467\n",
            "Epoch 525/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1735 - val_loss: 0.0474\n",
            "Epoch 526/600\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2247 - val_loss: 0.0471\n",
            "Epoch 527/600\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1891 - val_loss: 0.0476\n",
            "Epoch 528/600\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1496 - val_loss: 0.0481\n",
            "Epoch 529/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1928 - val_loss: 0.0481\n",
            "Epoch 530/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2017 - val_loss: 0.0479\n",
            "Epoch 531/600\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1744 - val_loss: 0.0479\n",
            "Epoch 532/600\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1612 - val_loss: 0.0486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faad7724f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "x_ovpjk1NlhA",
        "outputId": "32aebfa8-a928-4321-85f6-cd6491feee5d"
      },
      "source": [
        "pd.DataFrame(model.history.history).plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faad6db0c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgZFErI-NXjB",
        "outputId": "fb8e446d-db9f-45d3-f1e8-5127f6700498"
      },
      "source": [
        "predictions=model.predict_classes(X_test, batch_size=15, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUyDkivnPGy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf566367-b269-4ce8-9522-f9ec7edbcf8c"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 1, 1, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
              "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
              "       0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otKZ28ZnTTwR",
        "outputId": "fdca00cb-a68e-47c7-e5ed-9338c1dcd0d5"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjDRjB3CPVX1",
        "outputId": "bb8a550a-e077-461b-fdd2-22aefb5ec4f1"
      },
      "source": [
        "print(classification_report(encoded_y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.97      0.97        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-CndJ2qRCJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f4c52e9-8985-4d19-a13e-600df8242aaa"
      },
      "source": [
        "print(confusion_matrix(encoded_y_test,predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[19  0  0]\n",
            " [ 0 12  1]\n",
            " [ 0  0 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXB5yYNCVnSg"
      },
      "source": [
        "trying to predict a new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qco9R7LFU0w6"
      },
      "source": [
        "x_new=np.array([1,2.3,3,5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcgTMobfV3cI",
        "outputId": "c69467ac-e970-4365-ecd2-a5da17bc3cc3"
      },
      "source": [
        "result=model.predict_classes(x_new.reshape(1,-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSYuOGK8V9A5",
        "outputId": "a02a332c-561d-4370-ed85-d1f25e6d16c3"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDWBqwO9WnAU",
        "outputId": "85277e52-8e58-4dcf-8e7b-003fefde78fc"
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-_KtEKXW14T",
        "outputId": "fee4ac6f-d294-48bb-c8b5-c3b5d08ff975"
      },
      "source": [
        "result1=model.predict_classes(X_test[0].reshape(1,-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vreVqEpW__z",
        "outputId": "0b167fa2-03f6-4f2d-f01a-1b8826e0d787"
      },
      "source": [
        "result1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 290
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD6q-hF4XD0y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}